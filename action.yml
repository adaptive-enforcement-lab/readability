name: 'Documentation Readability Analyzer'
description: 'Analyze documentation readability and content quality metrics including Flesch-Kincaid, ARI, Gunning Fog, and more. Enforce thresholds in CI.'
author: 'Adaptive Enforcement Lab'

branding:
  icon: 'book-open'
  color: 'blue'

inputs:
  path:
    description: 'Path to analyze (file or directory)'
    required: false
    default: 'docs/'
  format:
    description: 'Output format (table, markdown, json, summary, report)'
    required: false
    default: 'markdown'
  config:
    description: 'Path to config file'
    required: false
    default: ''
  check:
    description: 'Enable check mode (fail on threshold violations)'
    required: false
    default: 'false'
  max-grade:
    description: 'Maximum Flesch-Kincaid grade level'
    required: false
    default: ''
  max-ari:
    description: 'Maximum ARI score'
    required: false
    default: ''
  max-lines:
    description: 'Maximum lines per file'
    required: false
    default: ''
  summary:
    description: 'Write formatted report to job summary (default: true)'
    required: false
    default: 'true'
  summary-title:
    description: 'Title for the job summary section'
    required: false
    default: 'Documentation Readability Report'
  version:
    description: 'Version of readability to use (default: latest)'
    required: false
    default: 'latest'

outputs:
  report:
    description: 'Analysis report in JSON format'
    value: ${{ steps.analyze.outputs.report }}
  passed:
    description: 'Whether all thresholds were met (true/false)'
    value: ${{ steps.analyze.outputs.passed }}
  files-analyzed:
    description: 'Number of files analyzed'
    value: ${{ steps.analyze.outputs.files-analyzed }}

runs:
  using: 'composite'
  steps:
    - name: Download readability binary
      id: download
      shell: bash
      run: |
        VERSION="${{ inputs.version }}"

        # Get latest version if not specified
        if [ "$VERSION" = "latest" ]; then
          VERSION=$(curl -sL "https://api.github.com/repos/adaptive-enforcement-lab/readability/releases/latest" | jq -r '.tag_name // empty')
          if [ -z "$VERSION" ]; then
            echo "::error::Failed to fetch latest version"
            exit 1
          fi
        fi

        echo "version=$VERSION" >> "$GITHUB_OUTPUT"

        # Detect platform
        OS="linux"
        ARCH="amd64"
        if [ "$RUNNER_ARCH" = "ARM64" ]; then
          ARCH="arm64"
        fi

        # Download and extract
        URL="https://github.com/adaptive-enforcement-lab/readability/releases/download/${VERSION}/readability_${OS}_${ARCH}.tar.gz"
        echo "Downloading readability ${VERSION} from ${URL}"

        curl -sL "$URL" -o /tmp/readability.tar.gz
        tar -xzf /tmp/readability.tar.gz -C /tmp
        chmod +x /tmp/readability_${OS}_${ARCH}
        mv /tmp/readability_${OS}_${ARCH} /tmp/readability

        echo "Downloaded readability ${VERSION}"

    - name: Run analysis
      id: analyze
      shell: bash
      run: |
        ARGS=""

        # Auto-detect config file if not specified
        if [ -n "${{ inputs.config }}" ]; then
          ARGS="$ARGS --config ${{ inputs.config }}"
        elif [ -f ".readability.yml" ]; then
          ARGS="$ARGS --config .readability.yml"
        fi

        # Always use JSON for capturing outputs, then convert for display
        ARGS="$ARGS --format json"

        if [ "${{ inputs.check }}" = "true" ]; then
          ARGS="$ARGS --check"
        fi

        if [ -n "${{ inputs.max-grade }}" ]; then
          ARGS="$ARGS --max-grade ${{ inputs.max-grade }}"
        fi

        if [ -n "${{ inputs.max-ari }}" ]; then
          ARGS="$ARGS --max-ari ${{ inputs.max-ari }}"
        fi

        if [ -n "${{ inputs.max-lines }}" ]; then
          ARGS="$ARGS --max-lines ${{ inputs.max-lines }}"
        fi

        # Run analysis and capture output (stderr separate from stdout)
        set +e
        OUTPUT=$(/tmp/readability $ARGS ${{ inputs.path }} 2>/dev/null)
        EXIT_CODE=$?
        set -e

        # Parse JSON output for metrics (ensure single-line numeric values)
        FILES_ANALYZED=$(echo "$OUTPUT" | jq -r 'if type == "array" then length else 0 end' 2>/dev/null | head -1 || echo "0")
        FAILED_COUNT=$(echo "$OUTPUT" | jq -r '[.[] | select(.status == "fail")] | length' 2>/dev/null | head -1 || echo "0")

        # Ensure numeric values (fallback to 0 if not)
        FILES_ANALYZED="${FILES_ANALYZED:-0}"
        FAILED_COUNT="${FAILED_COUNT:-0}"
        [[ "$FILES_ANALYZED" =~ ^[0-9]+$ ]] || FILES_ANALYZED=0
        [[ "$FAILED_COUNT" =~ ^[0-9]+$ ]] || FAILED_COUNT=0

        if [ "$FAILED_COUNT" -eq 0 ]; then
          PASSED="true"
        else
          PASSED="false"
        fi

        # Set outputs
        echo "files-analyzed=$FILES_ANALYZED" >> "$GITHUB_OUTPUT"
        echo "passed=$PASSED" >> "$GITHUB_OUTPUT"

        # Store full report
        {
          echo "report<<EOF"
          echo "$OUTPUT"
          echo "EOF"
        } >> "$GITHUB_OUTPUT"

        # Generate formatted markdown table with metric links to docs
        DOCS_BASE="https://readability.adaptive-enforcement-lab.com/latest/metrics"
        MARKDOWN_TABLE=$(echo "$OUTPUT" | jq -r --arg docs "$DOCS_BASE" '
          "| File | Lines | Read | [Grade](\($docs)/grade-level/#flesch-kincaid-grade-level) | [ARI](\($docs)/grade-level/#ari-automated-readability-index) | [Fog](\($docs)/grade-level/#gunning-fog-index) | [Ease](\($docs)/flesch-reading-ease/) | Status |",
          "|------|------:|-----:|------:|----:|----:|-----:|--------|",
          (.[] | "| \(.file) | \(.structural.lines) | \(if .structural.words < 200 then "<1m" else "\(.structural.words / 200 | floor)m" end) | \(.readability.flesch_kincaid_grade | . * 10 | round / 10) | \(.readability.ari | . * 10 | round / 10) | \(.readability.gunning_fog | . * 10 | round / 10) | \(.readability.flesch_reading_ease | . * 10 | round / 10) | \(.status) |")
        ' 2>/dev/null || echo "$OUTPUT")

        # Write to job summary if enabled
        if [ "${{ inputs.summary }}" = "true" ] && [ -n "$GITHUB_STEP_SUMMARY" ]; then
          {
            echo "## ${{ inputs.summary-title }}"
            echo ""
            echo "$MARKDOWN_TABLE"
            echo ""
            echo "_Files analyzed: ${FILES_ANALYZED} | Passed: $((FILES_ANALYZED - FAILED_COUNT)) | Failed: ${FAILED_COUNT}_"
          } >> "$GITHUB_STEP_SUMMARY"
        fi

        # Generate formatted output for display (stdout)
        # Skip verbose stdout if summary is enabled and format is markdown (already in summary)
        FORMAT="${{ inputs.format }}"
        SUMMARY_ENABLED="${{ inputs.summary }}"

        if [ "$SUMMARY_ENABLED" = "true" ] && [ "$FORMAT" = "markdown" ]; then
          # Only output a brief status line when markdown goes to summary
          echo "Readability analysis complete: ${FILES_ANALYZED} files, ${FAILED_COUNT} failed"
        else
          case "$FORMAT" in
            json)
              echo "$OUTPUT"
              ;;
            markdown|report)
              echo "$MARKDOWN_TABLE"
              ;;
            summary)
              echo "$OUTPUT" | jq -r '
                "Files analyzed: \(length)",
                "Passed: \([.[] | select(.status == "pass")] | length)",
                "Failed: \([.[] | select(.status == "fail")] | length)"
              ' 2>/dev/null || echo "$OUTPUT"
              ;;
            *)
              echo "$OUTPUT" | jq -r '.[] | "\(.file): Grade=\(.readability.flesch_kincaid_grade | . * 10 | round / 10), Status=\(.status)"' 2>/dev/null || echo "$OUTPUT"
              ;;
          esac
        fi

        # Exit with original code to respect --check
        exit $EXIT_CODE
